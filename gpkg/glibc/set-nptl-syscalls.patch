diff --git a/nptl/pthread_create.c b/nptl/pthread_create.c
index 9ae5423d..89b4da90 100644
--- a/nptl/pthread_create.c
+++ b/nptl/pthread_create.c
@@ -380,16 +380,6 @@ start_thread (void *arg)
       __libc_fatal ("Fatal glibc error: rseq registration failed\n");
   }
 
-#ifndef __ASSUME_SET_ROBUST_LIST
-  if (__nptl_set_robust_list_avail)
-#endif
-    {
-      /* This call should never fail because the initial call in init.c
-	 succeeded.  */
-      INTERNAL_SYSCALL_CALL (set_robust_list, &pd->robust_head,
-			     sizeof (struct robust_list_head));
-    }
-
   /* This is where the try/finally block should be created.  For
      compilers without that support we do use setjmp.  */
   struct pthread_unwind_buf unwind_buf;
diff --git a/sysdeps/nptl/_Fork.c b/sysdeps/nptl/_Fork.c
index 891ed8fb..dfe77d81 100644
--- a/sysdeps/nptl/_Fork.c
+++ b/sysdeps/nptl/_Fork.c
@@ -49,8 +49,6 @@ _Fork (void)
       self->robust_prev = &self->robust_head;
 #endif
       self->robust_head.list = &self->robust_head;
-      INTERNAL_SYSCALL_CALL (set_robust_list, &self->robust_head,
-			     sizeof (struct robust_list_head));
       call_function_static_weak (__getrandom_fork_subprocess);
     }
 
diff --git a/sysdeps/nptl/dl-tls_init_tp.c b/sysdeps/nptl/dl-tls_init_tp.c
index f487bfb6..8c190182 100644
--- a/sysdeps/nptl/dl-tls_init_tp.c
+++ b/sysdeps/nptl/dl-tls_init_tp.c
@@ -90,14 +90,9 @@ __tls_init_tp (void)
     pd->robust_head.futex_offset = (offsetof (pthread_mutex_t, __data.__lock)
                                     - offsetof (pthread_mutex_t,
                                                 __data.__list.__next));
-    int res = INTERNAL_SYSCALL_CALL (set_robust_list, &pd->robust_head,
-                                     sizeof (struct robust_list_head));
-    if (!INTERNAL_SYSCALL_ERROR_P (res))
-      {
 #ifndef __ASSUME_SET_ROBUST_LIST
-        __nptl_set_robust_list_avail = true;
+    __nptl_set_robust_list_avail = false;
 #endif
-      }
   }
 
   {
diff --git a/sysdeps/unix/sysv/linux/rseq-internal.h b/sysdeps/unix/sysv/linux/rseq-internal.h
index f89e7842..707460d5 100644
--- a/sysdeps/unix/sysv/linux/rseq-internal.h
+++ b/sysdeps/unix/sysv/linux/rseq-internal.h
@@ -93,45 +93,11 @@ RSEQ_SELF (void)
   return (struct rseq_area *) ((char *) __thread_pointer () + __rseq_offset);
 }
 
-#ifdef RSEQ_SIG
 static inline bool
 rseq_register_current_thread (struct pthread *self, bool do_rseq)
 {
-  if (do_rseq)
-    {
-      unsigned int size =  __rseq_size;
-
-      /* The feature size can be smaller than the minimum rseq area size of 32
-         bytes accepted by the syscall, if this is the case, bump the size of
-         the registration to the minimum.  The 'extra TLS' block is always at
-         least 32 bytes. */
-      if (size < RSEQ_AREA_SIZE_INITIAL)
-        size = RSEQ_AREA_SIZE_INITIAL;
-
-      /* Initialize the rseq fields that are read by the kernel on
-         registration, there is no guarantee that struct pthread is
-         cleared on all architectures.  */
-      RSEQ_SETMEM (cpu_id, RSEQ_CPU_ID_UNINITIALIZED);
-      RSEQ_SETMEM (cpu_id_start, 0);
-      RSEQ_SETMEM (rseq_cs, 0);
-      RSEQ_SETMEM (flags, 0);
-
-      int ret = INTERNAL_SYSCALL_CALL (rseq, RSEQ_SELF (), size, 0, RSEQ_SIG);
-      if (!INTERNAL_SYSCALL_ERROR_P (ret))
-        return true;
-    }
-  /* When rseq is disabled by tunables or the registration fails, inform
-     userspace by setting 'cpu_id' to RSEQ_CPU_ID_REGISTRATION_FAILED.  */
   RSEQ_SETMEM (cpu_id, RSEQ_CPU_ID_REGISTRATION_FAILED);
   return false;
 }
-#else /* RSEQ_SIG */
-static inline bool
-rseq_register_current_thread (struct pthread *self, bool do_rseq)
-{
-  RSEQ_SETMEM (cpu_id, RSEQ_CPU_ID_REGISTRATION_FAILED);
-  return false;
-}
-#endif /* RSEQ_SIG */
 
 #endif /* rseq-internal.h */
